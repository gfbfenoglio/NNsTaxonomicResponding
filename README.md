# NNsTaxonomicResponding
A neural network model for taxonomic responding with realistic visual inputs

## Abstract
In this work we propose a neural network model for taxonomic responding with realistic visual inputs. The model learns word-object associations, and generalizes those associations to objects belonging to the same category. It takes visual inputs from the ImageNet dataset, and simplified acoustic stimuli. It is made of a convolutional deep neural network processing the visual input, a visual and acoustic self-organizing maps that topologically organize the visual and acoustic inputs respectively, a set of Hebbian connections connecting the visual and acoustic self-organizing maps. 


